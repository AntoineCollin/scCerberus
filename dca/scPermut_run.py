import argparse
from dca.utils import str2bool,tuple_to_scalar

parser = argparse.ArgumentParser()

# parser.add_argument('--run_file', type = , default = , help ='')
# parser.add_argument('--workflow_ID', type = , default = , help ='')
parser.add_argument('--dataset_name', type = str, default = 'disco_ajrccm_downsampled', help ='Name of the dataset to use, should indicate a raw h5ad AnnData file')
parser.add_argument('--class_key', type = str, default = 'celltype_lv2_V3', help ='Key of the class to classify')
parser.add_argument('--batch_key', type = str, default = 'manip', help ='Key of the batches')
parser.add_argument('--filter_min_counts', type=str2bool, nargs='?',const=True, default=True, help ='Filters genes with <1 counts')# TODO :remove, we always want to do that
parser.add_argument('--normalize_size_factors', type=str2bool, nargs='?',const=True, default=True, help ='Weither to normalize dataset or not')
parser.add_argument('--scale_input', type=str2bool, nargs='?',const=True, default=True, help ='Weither to scale input the count values')
parser.add_argument('--logtrans_input', type=str2bool, nargs='?',const=True, default=True, help ='Weither to log transform count values')
parser.add_argument('--use_hvg', type=int, nargs='?', const=10000, default=None, help = "Number of hvg to use. If no tag, don't use hvg.")
# parser.add_argument('--reduce_lr', type = , default = , help ='')
# parser.add_argument('--early_stop', type = , default = , help ='')
parser.add_argument('--batch_size', type = int, nargs='?', default = 128, help ='Training batch size')
# parser.add_argument('--verbose', type = , default = , help ='')
# parser.add_argument('--threads', type = , default = , help ='')
parser.add_argument('--mode', type = str, default = 'percentage', help ='Train test split mode to be used by Dataset.train_split')
parser.add_argument('--pct_split', type = float,nargs='?', default = 0.9, help ='')
parser.add_argument('--obs_key', type = str,nargs='?', default = 'manip', help ='')
parser.add_argument('--n_keep', type = int,nargs='?', default = None, help ='')
parser.add_argument('--split_strategy', type = str,nargs='?', default = None, help ='')
parser.add_argument('--keep_obs', type = str,nargs='?',default = None, help ='')
parser.add_argument('--train_test_random_seed', type = float,nargs='?', default = 0, help ='')
parser.add_argument('--obs_subsample', type = str,nargs='?', default = None, help ='')
parser.add_argument('--make_fake', type=str2bool, nargs='?',const=False, default=False, help ='')
parser.add_argument('--true_celltype', type = str,nargs='?', default = None, help ='')
parser.add_argument('--false_celltype', type = str,nargs='?', default = None, help ='')
parser.add_argument('--pct_false', type = float,nargs='?', default = None, help ='')
parser.add_argument('--clas_loss_fn', type = str,nargs='?', choices = ['MSE'], default = 'MSE' , help ='Loss of the classification branch')
parser.add_argument('--dann_los_fn', type = str,nargs='?', choices = ['categorical_crossentropy'], default ='categorical_crossentropy', help ='Loss of the DANN branch')
parser.add_argument('--rec_loss_fn', type = str,nargs='?', choices = ['categorical_crossentropy'], default ='categorical_crossentropy', help ='Reconstruction loss of the autoencoder')
parser.add_argument('--weight_decay', type = float,nargs='?', default = 1e-4, help ='Weight decay applied by th optimizer')
parser.add_argument('--learning_rate', type = float,nargs='?', default = 0.001, help ='Starting learning rate for training')
parser.add_argument('--optimizer_type', type = str, nargs='?',choices = ['adam','adamw','rmsprop'], default = 'adam' , help ='Name of the optimizer to use')
parser.add_argument('--clas_w', type = float,nargs='?', default = 0.1, help ='Wight of the classification loss')
parser.add_argument('--dann_w', type = float,nargs='?', default = 0.1, help ='Wight of the DANN loss')
parser.add_argument('--rec_w', type = float,nargs='?', default = 0.8, help ='Wight of the reconstruction loss')
parser.add_argument('--ae_hidden_size', type = int,nargs='+', default = [128,64,128], help ='Hidden sizes of the successive ae layers')
parser.add_argument('--ae_hidden_dropout', type =float, nargs='?', default = None, help ='')
parser.add_argument('--ae_activation', type = str ,nargs='?', default = 'relu' , help ='')
parser.add_argument('--ae_output_activation', type = str,nargs='?', default = 'linear', help ='')
parser.add_argument('--ae_init', type = str,nargs='?', default = 'glorot_uniform', help ='')
parser.add_argument('--ae_batchnorm', type=str2bool, nargs='?',const=True, default=True , help ='')
parser.add_argument('--ae_l1_enc_coef', type = float,nargs='?', default = None, help ='')
parser.add_argument('--ae_l2_enc_coef', type = float,nargs='?', default = None, help ='')
parser.add_argument('--class_hidden_size', type = int,nargs='+', default = [64], help ='Hidden sizes of the successive classification layers')
parser.add_argument('--class_hidden_dropout', type =float, nargs='?', default = None, help ='')
parser.add_argument('--class_batchnorm', type=str2bool, nargs='?',const=True, default=True , help ='')
parser.add_argument('--class_activation', type = str ,nargs='?', default = 'relu' , help ='')
parser.add_argument('--class_output_activation', type = str,nargs='?', default = 'softmax', help ='')
parser.add_argument('--dann_hidden_size', type = int,nargs='?', default = [64], help ='')
parser.add_argument('--dann_hidden_dropout', type =float, nargs='?', default = None, help ='')
parser.add_argument('--dann_batchnorm', type=str2bool, nargs='?',const=True, default=True , help ='')
parser.add_argument('--dann_activation', type = str ,nargs='?', default = 'relu' , help ='')
parser.add_argument('--dann_output_activation', type = str,nargs='?', default = 'softmax', help ='')
parser.add_argument('--training_scheme', type = str,nargs='?', default = ' ', help ='')

args = parser.parse_args()
